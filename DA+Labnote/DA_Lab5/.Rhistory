library(textdata)
afinn <- get_sentiments("afinn")
afinn %>%
slice_sample(n = 15) %>%
arrange(desc(value))
arxiv_words %>%
inner_join(afinn, by = "word") %>%
select(word, id, value)
arxiv_sentiments <- arxiv_words %>%
left_join(afinn, by = "word") %>%
group_by(id) %>%
summarize(
num_words = n(),
sentiment = sum(value, na.rm = TRUE),
.groups = "drop"
) %>%
mutate(sentiment_per_word = sentiment / num_words) %>%
arrange(desc(sentiment))
arxiv_papers <- arxiv_papers %>%
left_join(arxiv_sentiments, by = "id")
arxiv_papers %>%
skim(sentiment, sentiment_per_word)
most_positive <- arxiv_papers %>%
filter(sentiment_per_word == max(sentiment_per_word)) %>%
pull(abstract)
strwrap(most_positive)
ggplot(
arxiv_papers,
aes(
x = submitted, y = sentiment_per_word,
color = field == "cs"
)
) +
geom_smooth(se = TRUE) +
scale_color_brewer("Computer Science?", palette = "Set2") +
labs(x = "Date submitted", y = "Sentiment score per word")
arxiv_words %>%
count(word) %>%
arrange(desc(n)) %>%
head()
tidy_DTM <- arxiv_words %>%
count(id, word) %>%
bind_tf_idf(word, id, n)
tidy_DTM %>%
arrange(desc(tf)) %>%
head()
tidy_DTM %>%
arrange(desc(idf), desc(n)) %>%
head()
arxiv_papers %>%
pull(abstract) %>%
str_subset("wildfire") %>%
strwrap() %>%
head()
tidy_DTM %>%
filter(word == "implications")
tidy_DTM %>%
filter(id == "1809.02408v2") %>%
arrange(desc(tf_idf)) %>%
head()
tidy_DTM %>%
filter(word == "covid") %>%
arrange(desc(tf_idf)) %>%
head() %>%
left_join(select(arxiv_papers, id, abstract), by = "id")
tidy_DTM %>%
arrange(desc(tf_idf)) %>%
head() %>%
left_join(select(arxiv_papers, id, abstract), by = "id")
tm_DTM <- arxiv_words %>%
count(id, word) %>%
cast_dtm(id, word, n, weighting = tm::weightTfIdf)
tm_DTM
library(tm)
findFreqTerms(tm_DTM, lowfreq = 7)
library(purrr)
tm_DTM %>%
as.matrix() %>%
as_tibble() %>%
map_dbl(sum) %>%
sort(decreasing = TRUE) %>%
head()
library(rvest)
url <- "http://en.wikipedia.org/wiki/List_of_songs_recorded_by_the_Beatles"
tables <- url %>%
read_html() %>%
html_nodes("table")
Beatles_songs <- tables %>%
purrr::pluck(3) %>%
html_table(fill = TRUE) %>%
janitor::clean_names() %>%
select(song, lead_vocal_s_d)
glimpse(Beatles_songs)
Beatles_songs <- Beatles_songs %>%
mutate(song = str_remove_all(song, pattern = '\\"')) %>%
rename(vocals = lead_vocal_s_d)
Beatles_songs %>%
group_by(vocals) %>%
count() %>%
arrange(desc(n))
Beatles_songs %>%
pull(vocals) %>%
str_subset("McCartney") %>%
length()
Beatles_songs %>%
pull(vocals) %>%
str_subset("Lennon") %>%
length()
Beatles_songs %>%
pull(vocals) %>%
str_subset("(McCartney|Lennon)") %>%
length()
pj_regexp <- "(McCartney|Lennon).*(McCartney|Lennon)"
Beatles_songs %>%
pull(vocals) %>%
str_subset(pj_regexp) %>%
length()
Beatles_songs %>%
filter(str_detect(vocals, pj_regexp)) %>%
select(song, vocals) %>%
head()
Beatles_songs %>%
unnest_tokens(word, song) %>%
anti_join(get_stopwords(), by = "word") %>%
count(word, sort = TRUE) %>%
arrange(desc(n)) %>%
head()
library(tidyverse)
library(mdsr)
library(nycflights13)
SF <- flights %>%
filter(dest == "SFO", !is.na(arr_delay))
three_flights <- SF %>%
slice_sample(n = 3, replace = FALSE) %>%
select(year, month, day, dep_time)
three_flights
three_flights %>% slice_sample(n = 3, replace = TRUE)
three_flights %>% slice_sample(n = 3, replace = TRUE)
n <- 200
orig_sample <- SF %>%
slice_sample(n = n, replace = FALSE)
orig_sample %>%
slice_sample(n = n, replace = TRUE) %>%
summarize(mean_arr_delay = mean(arr_delay))
num_trials <- 200
sf_200_bs <- 1:num_trials %>%
map_dfr(
~orig_sample %>%
slice_sample(n = n, replace = TRUE) %>%
summarize(mean_arr_delay = mean(arr_delay))
) %>%
mutate(n = n)
sf_200_bs %>%
skim(mean_arr_delay)
sf_200_pop <- 1:num_trials %>%
map_dfr(
~SF %>%
slice_sample(n = n, replace = TRUE) %>%
summarize(mean_arr_delay = mean(arr_delay))
) %>%
mutate(n = n)
sf_200_pop %>%
skim(mean_arr_delay)
strings <- c(
"This string has no hashtags",
"#hashtag city!",
"This string has a #hashtag",
"This string has #two #hashtags"
)
text_lines <- tibble(
lines = c("This is the first line.",
"This line is hyphen- ",
"ated. It's very diff-",
"icult to use at present.")
)
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
qnorm(0.995)
round(qnorm(0.995), 3)
round(qnorm(0.995), 2)
qnorm(0.995)
round(qnorm(0.995), 2)
library('mosaicData')
Gestation
dfq2 <- Gestation
View(dfq2)
mean(dfq2$age)
mean(dfq2$age)
mean(dfq2$age)
dfq2$age
mean(dfq2$age, na.rm = TRUE)
?mean
sd(dfq2$age)
sd(dfq2$age, na.rm = TRUE)
CI_q2 <- c(q2_mean - 2*q2_sd, q2_mean + 2*q2_sd)
dfq2 <- Gestation
q2_mean <- mean(dfq2$age, na.rm = TRUE)
q2_sd <- sd(dfq2$age, na.rm = TRUE)
CI_q2 <- c(q2_mean - 2*q2_sd, q2_mean + 2*q2_sd)
CI_q2
q3_median <- median(dfq2$age)
q3_median
q3_median <- median(dfq2$age, na.rm = TRUE)
q3_median
dfq2 <- Gestation %>% select(is.na(age) == FALSE)
dfq2 <- Gestation %>% select(is.na(dfq2$age) == FALSE)
dfq2 <- Gestation %>% select(is.na(dfq2$age) == 0)
is.na(dfq2$age)
dfq2 <- Gestation %>% mutate(age_na = is.na(dfq2$age)) %>% select(age_na == 0)
dfq2 <- Gestation %>% mutate(age_na = is.na(dfq2$age)) %>% select(age_na == 0)
dfq2 <- Gestation %>% mutate(age_na = is.na(age)) %>% select(age_na == 0)
dfq2 <- Gestation %>% mutate(age_na = is.na(age))
View(dfq2)
dfq2 <- Gestation %>% mutate(age_na = is.na(age)) %>% select(age_na == FALSE)
dfq2 <- Gestation %>% mutate(age_na = is.na(age)) %>% select(age_na == FALSE)
dfq2 <- Gestation %>% mutate(age_na = is.na(age)) %>% filter(age_na == FALSE)
dfq2 <- Gestation %>% filter(is.na(age) == FALSE)
View(dfq2)
dfq2 <- Gestation %>% filter(is.na(age) == FALSE)
q2_mean <- mean(dfq2$age)
q2_sd <- sd(dfq2$age)
CI_q2 <- c(q2_mean - 2*q2_sd, q2_mean + 2*q2_sd)
CI_q2
q3_median <- median(dfq2$age)
q3_median
dfq2_booted <- dfq2 %>%
slice_sample(n = 100, replace = TRUE) %>%
select(age)
View(dfq2_booted)
dfq2_booted <- dfq2 %>%
slice_sample(n = 100, replace = TRUE) %>%
summarise(median(age))
dfq2_booted
?map_dfr
q3_median <- median(dfq2$age)
q3_median
n_trial <- 200
dfq2_booted <- 1:n_trial %>%
map_dfr(
~dfq2 %>%
slice_sample(n = 100, replace = TRUE) %>%
summarise(median(age))
) %>% mutate(n = 100)
dfq2_booted
n_trial <- 200
dfq2_booted <- 1:n_trial %>%
map_dfr(
~dfq2 %>%
slice_sample(n = 100, replace = TRUE) %>%
summarise(median(age))
) %>% mutate(n = 100)
skim(dfq2_booted)
n_trial <- 200
dfq2_booted <- 1:n_trial %>%
map_dfr(
~dfq2 %>%
slice_sample(n = 100, replace = TRUE) %>%
summarise(median(age))
) %>% mutate(n = 100)
skim(dfq2_booted)
q3_median <- median(dfq2$age)
q3_median
n_trial <- 200
dfq2_booted <- 1:n_trial %>%
map_dfr(
~dfq2 %>%
slice_sample(n = 100, replace = TRUE) %>%
summarise(median(age))
) %>% mutate(n = 100)
skim(dfq2_booted)
#switch()
?skim
summary(dfq2_booted)
sd(dfq2_booted$`median(age)`)
q3_sd <- sd(dfq2_booted$`median(age)`)
q3_med <- mean(dfq2_booted$`median(age)`)
q3_sd <- sd(dfq2_booted$`median(age)`)
q3_median <- median(dfq2$age)
q3_median
n_trial <- 200
dfq2_booted <- 1:n_trial %>%
map_dfr(
~dfq2 %>%
slice_sample(n = 100, replace = TRUE) %>%
summarise(median(age))
) %>% mutate(n = 100)
q3_med <- mean(dfq2_booted$`median(age)`)
q3_sd <- sd(dfq2_booted$`median(age)`)
CI_q3 <- c(q3_mean - 2*q3_sd, q3_mean + 2*q3_sd)
q3_median <- median(dfq2$age)
q3_median
n_trial <- 200
dfq2_booted <- 1:n_trial %>%
map_dfr(
~dfq2 %>%
slice_sample(n = 100, replace = TRUE) %>%
summarise(median(age))
) %>% mutate(n = 100)
q3_med <- mean(dfq2_booted$`median(age)`)
q3_sd <- sd(dfq2_booted$`median(age)`)
CI_q3 <- c(q3_med - 2*q3_sd, q3_med + 2*q3_sd)
CI_q3
dfq2
View(dfq2)
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('mosaicData')
library('mdsr')
lm(wt ~ age, data = dfq2)
lmq4 <- lm(wt ~ age, data = dfq2)
summary(lmq4)
dfq2_booted <- 1:200 %>%
map_dfr(
~dfq2 %>%
slice_sample(n = 100, replace = TRUE) %>%
summarise(lm(wt ~ age, data = dfq2))
) %>% mutate(n = 100)
dfq4_temp <- slice_sample(dfq2, n = 100, replace = TRUE)
lmq4_temp <- lm(wt ~ age, data = dfq4_temp)
coef(lmq4_temp)
dfq4_bootstrap <- tibble()
for (i in 1:200) {
dfq4_temp <- slice_sample(dfq2, n = 100, replace = TRUE)
lmq4_temp <- lm(wt ~ age, data = dfq4_temp)
add_row(dfq4_bootstrap, coef(lmq4_temp))
}
View(lmq4)
dfq4_bootstrap <- tibble()
dfq4_bootstrap <- colnames(c('intercept', 'age'))
for (i in 1:200) {
dfq4_temp <- slice_sample(dfq2, n = 100, replace = TRUE)
lmq4_temp <- lm(wt ~ age, data = dfq4_temp)
add_row(dfq4_bootstrap, intercept = coef(lmq4_temp)[0], age = coef(lmq4_temp)[1])
}
dfq4_bootstrap <- tibble()
dfq4_bootstrap <- colnames(c('intercept', 'age'))
dfq4_bootstrap <- tibble()
dfq4_bootstrap <- colnames(dfq4_bootstrap, c('intercept', 'age'))
?colnames
dfq4_bootstrap <- tibble()
colnames(dfq4_bootstrap) <- c('intercept', 'age')
View(dfq4_bootstrap)
for (i in 1:200) {
dfq4_temp <- slice_sample(dfq2, n = 100, replace = TRUE)
lmq4_temp <- lm(wt ~ age, data = dfq4_temp)
add_row(dfq4_bootstrap, intercept = coef(lmq4_temp)[0], age = coef(lmq4_temp)[1])
}
dfq4_bootstrap <- tibble()
list(dfq4_bootstrap, coef(lmq4_temp))
dfq4_bootstrap <- tibble()
for (i in 1:200) {
dfq4_temp <- slice_sample(dfq2, n = 100, replace = TRUE)
lmq4_temp <- lm(wt ~ age, data = dfq4_temp)
list(dfq4_bootstrap, coef(lmq4_temp))
}
dfq4_bootstrap <- tibble()
dfq4_bootstrap <- tibble()
for (i in 1:200) {
dfq4_temp <- slice_sample(dfq2, n = 100, replace = TRUE)
lmq4_temp <- lm(wt ~ age, data = dfq4_temp)
dfq4_bootstrap <- tibble(dfq4_bootstrap, coef(lmq4_temp))
}
dfq4_bootstrap <- list(dfq4_bootstrap, coef(lmq4_temp))
dfq4_bootstrap <- tibble()
dfq4_bootstrap <- tibble()
for (i in 1:200) {
dfq4_temp <- slice_sample(dfq2, n = 100, replace = TRUE)
lmq4_temp <- lm(wt ~ age, data = dfq4_temp)
dfq4_bootstrap <- list(dfq4_bootstrap, coef(lmq4_temp))
}
dfq4_bootstrap <- rbind(dfq4_bootstrap, coef(lmq4_temp))
dfq4_bootstrap <- tibble()
for (i in 1:200) {
dfq4_temp <- slice_sample(dfq2, n = 100, replace = TRUE)
lmq4_temp <- lm(wt ~ age, data = dfq4_temp)
dfq4_bootstrap <- rbind(dfq4_bootstrap, coef(lmq4_temp))
}
View(dfq4_bootstrap)
colnames(dfq4_bootstrap) <- c('intercept', 'age')
dfq4_bootstrap
Macbeth_raw
Macbeth <- Macbeth_raw %>%
str_split()
Macbeth <- Macbeth_raw %>%
str_split('\r\r')
View(Macbeth)
Macbeth <- Macbeth_raw %>%
str_split('\r\r') %>%
pluck([1])
Macbeth <- Macbeth_raw %>%
str_split('\r\r') %>%
pluck(1)
Macbeth
Macbeth <- Macbeth_raw %>%
str_split('\r\n') %>%
pluck(1)
Macbeth
Macbeth <- Macbeth_raw %>%
str_split('\r\n') %>%
pluck(1)
Macbeth <- Macbeth_raw %>%
str_split('\r\n') %>%
pluck(1)
Macbeth %>%
str_detect('  \"(A-Z)')
Macbeth %>%
str_extract('  \"(A-Z)')
Macbeth %>%
str_subset('  \"(A-Z)')
Macbeth %>%
str_subset('^  +[A-Z]')
Macbeth %>%
str_subset('^  +[A-Z],')
Macbeth %>%
str_subset('^  +[A-Z]')
Macbeth %>%
str_subset('^  +[A-Z],')
Macbeth %>%
str_subset('^  [+A-Z],')
Macbeth %>%
str_subset('^  [+A-Z],')
Macbeth %>%
str_subset('^  +[A-Z],')
Macbeth %>%
str_subset('^  +[A-Z]\,')
Macbeth %>%
str_subset('^  +[A-Z],')
Macbeth %>%
str_subset('^  +[A-Z]')
Macbeth %>%
str_subset('^  [A-Z]+,')
Macbeth %>%
str_subset('^ [A-Z]+,')
Macbeth %>%
str_subset('^   [A-Z]+,')
Macbeth %>%
str_subset('^  [A-Z]+,')
Macbeth %>%
str_subset('^  [A-Z],')
Macbeth %>%
str_subset('^  [A-Z]*,')
Macbeth %>%
str_subset('^  [A-Z]+,')
Macbeth %>%
str_subset('[A-z]+-[A-z]+')
Macbeth %>%
str_extract('[A-z]+-[A-z]+')
Macbeth %>%
str_subset('[A-z]+-[A-z]+')
Macbeth %>%
str_detect('[A-z]+-[A-z]+')
Macbeth %>%
str_subset('[A-z]+-[A-z]+')
Macbeth %>%
str_extract('^  [A-Z]+,')
Macbeth %>%
str_detect('^  [A-Z]+,')
Macbeth %>%
str_subset('[A-z]+-[A-z]+') %>%
str_extract('[A-z]+-[A-z]+')
Macbeth %>%
str_subset('[A-z]+-[A-z]+') %>%
str_extract('[A-z]+-[A-z]+')
strings <- c(
"This string has no hashtags",
"#hashtag city!",
"This string has a #hashtag",
"This string has #two #hashtags"
)
str_subset(strings, '^#')
str_detect(strings, '^#')
str_detect(strings, '^#'|' #')
strings <- c(
"This string has no hashtags",
"#hashtag city!",
"This string has a #hashtag",
"This string has #two #hashtags"
)
str_detect(strings, '^#'|' #')
str_detect(strings, c('^#'|' #'))
str_detect(strings, '(^| )#')
str_detect(strings, '(^| )#[A-z|0-9|]+( |$)')
str_detect(HE0DShoT, '(^| )#[A-z|0-9]+( |$)')
str_detect('HE0DShoT', '(^| )#[A-z|0-9]+( |$)')
str_detect(strings, '(^| )#[A-z0-9]+( |$)')
str_detect(strings, '(^| )#[A-z0-9]+( |$)')
str_detect('HE0DShoT', '(^| )#[A-z|0-9]+( |$)')
str_detect('HE0DShoT', '(^| )#[A-z0-9]+( |$)')
str_detect(strings, '(^| )#[A-z0-9]+( |$)')
str_detect('HE0DShoT', '(^| )#[A-z0-9]+( |$)')
str_detect('HE0DShoT', '(^| )#[A-z|0-9]+( |$)')
str_detect('#HE0DShoT', '(^| )#[A-z|0-9]+( |$)')
str_detect('#HE0DShoT', '(^| )#[A-z0-9]+( |$)')
strings <- c(
"This string has no hashtags",
"#hashtag city!",
"This string has a #hashtag",
"This string has #two #hashtags"
)
str_detect(strings, '(^| )#[A-z0-9]+( |$)')
text_lines <- tibble(
lines = c("This is the first line.",
"This line is hyphen- ",
"ated. It's very diff-",
"icult to use at present.")
)
text_lines
remove_hyphen <- function(strsq) {
if
}
Macbeth %>%
str_subset('^  [A-Z]+,')
