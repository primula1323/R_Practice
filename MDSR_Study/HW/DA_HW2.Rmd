---
title: "Data Analysis and Lab HW2"
author: "Na SeungChan"
date: "`r Sys.Date()`"
mainfont : NanumGothic
output:
  html_document:
    df_print: paged
  pdf_document:
    latex_engine: xelatex
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(NHANES)
library(glmnet)
```



Step 1. 


```{r}
df <- NHANES %>%
  mutate(male = ifelse(Gender == 'male', 1, 0), white = ifelse(Race1 == 'White', 1, 0), black = ifelse(Race1 == 'Black', 1, 0), hs = ifelse(Education == 'High School'|Education == 'Some College'|Education == 'College Grad', 1, 0), income_high = ifelse(HHIncome == "75000-99999"|HHIncome == "more 99999", 1, 0), income_low = ifelse(HHIncome == " 0-4999"|HHIncome == " 5000-9999"|HHIncome ==   "10000-14999"|HHIncome == "15000-19999"|HHIncome == "20000-24999", 1, 0), own = ifelse(HomeOwn == 'Own', 1, 0), BMI = BMI, Age = Age, dia_yes = ifelse(Diabetes == 'Yes', 1, 0)) %>%
  dplyr::select(male, white, black, hs, income_high, income_low, own, BMI, Age, dia_yes, Height) 

df <- cbind(df, complete.cases(df)) %>% filter(complete.cases(df) == TRUE)

nrow(df)
```

data transformation이 노가다인 건 계속 오류가 떠서 다 노가다로 쳐 놓고 보니 Education levels에 띄어쓰기가 들어가 있었던 걸 놓쳐서일 뿐..


---

# Problem 1

## (a)

```{r}
model1 <- lm(Height ~ Age, data = df)
summary(model1)
model2 <- lm(Height ~ poly(Age, 2), data = df)
summary(model2)
model3 <- lm(Height ~ poly(Age, 3), data = df)
summary(model3)
model4 <- lm(Height ~ poly(Age, 4), data = df)
summary(model4)
model5 <- lm(Height ~ poly(Age, 5), data = df)
summary(model5)
```


각 모델의 복잡성에 차이가 있으므로 bias-variance tradeoff 문제가 있어 R Squared만으로 고를 수는 없고(무조건 model5를 고르게 될 것이다.), C_p, BIC, adjusted R squared 등을 사용해야 한다. 이 경우 Adjusted R squared를 비교하여 사용하면 0.3879로 model3가 가장 높으므로 model3을 사용한다.



## (b)


```{r}
#predict(model3, newdata = df)
k <- predict(model3, df)

ggplot(data = df) +
  geom_point(mapping = aes(x = Age, y = Height)) +
  geom_smooth(mapping = aes(x = Age, y = predict(model3, df)))
```

(a)의 model3에 따라 3차식으로 fitting된 scatterplot이다.



## (c)

`leaps` package를 사용한다.

```{r}
library(leaps)
model5.full <- regsubsets(Height ~ poly(Age, 5), data = df)
model5.full
summary(model5.full)
```

nvmax option은 5개 변수만 사용하는 모델이 full model이므로 고려할 필요가 없다. 우선, 이를 통해 1개 변수만 사용할 때는 1차항만 사용(model1과 같음), 2개 변수만 사용할 때는 2차항까지만(model2와 같음), 3개 변수만 사용할 땐 3차항까지만(model3과 같음), 4개 변수만 사용할 때는 4차항까지만(model4와 같음) 사용하는 것이 각 변수 개수에서의 최고 모델임을 알 수 있다. 이제 이 중 어떤 모델을 선택할지 골라야 한다.

이 중 어떤 모델을 고르는 것이 적절한가? cross-vaildation, adjusted R squared, C_p, BIC 등 다양한 방법이 있다. 앞서 model 1~5를 adjusted r squared를 통해 비교하였으므로 이번에는 다른 방법을 사용한다.


```{r}
plot(summary(model5.full)$cp, type = 'l')
which.min(summary(model5.full)$cp)
```



## (d)

### forward selection

```{r}
model5.forward <- regsubsets(Height ~ poly(Age, 5), data = df, method = 'forward')
model5.forward
for.summary <- summary(model5.forward)
for.summary
plot(for.summary$bic)
which.min(for.summary$bic)
```

변수 개수별 best model은 앞의 결과와 똑같다. 이에 따라 각 복잡도멸 최고의 model을 BIC에 의해 구하면 위와 같다. model2를 이 경우 선택하게 된다.



### backward selection

```{r}
model5.backward <- regsubsets(Height ~ poly(Age, 5), data = df, method = 'backward')
model5.backward
back.summary <- summary(model5.backward)
back.summary
plot(back.summary$bic)
which.min(back.summary$bic)
```

변수 개수별 best model은 앞의 결과와 똑같다. 이에 따라 각 복잡도멸 최고의 model을 BIC에 의해 구하면 위와 같다. 이 경우에도 model2를 선택하게 된다.



## (e)


```{r}
set.seed(42)

df_age <- model.matrix(Height ~ poly(Age, 5), data = df)[, -1]
df_height <- df$Height

df_train <- sample(1:nrow(df_age), nrow(df_age)/2)
df_test <- (-df_train)
height.test <- df_height[df_test]

cv.out <- cv.glmnet(df_age[df_train, ], df_height[df_train], alpha = 1)
bestlam <- cv.out$lambda.min
bestlam
lasso_model <- glmnet(df_age, df_height, alpha = 1, lambda = bestlam)
lasso_model
summary(lasso_model)
coef(lasso_model)
```

bestlam의 결과는 위와 같이 출력되었다. (0.04961449)



# Exercise 2


## (a)

```{r}
lm1 <- glm(dia_yes ~ BMI, family = binomial, data = df)
summary(lm1)
```

BMI의 1단위 증가(1 증가)는 로그오즈비가 0.079042만큼 증가한다는 것을 의미한다. 즉 BMI와 당뇨병은 전반적으로 양의 상관관계가 있다.



## (b)

```{r}
lm2 <- glm(dia_yes ~ BMI + male + Age, family = binomial, data = df)
coef(lm2)
lm3 <- glm(dia_yes ~ BMI + male + Age + white + black, family = binomial, data = df)
coef(lm3)
lm4 <- glm(dia_yes ~ BMI + male + Age + white + black + income_high + income_low, family = binomial, data = df)
coef(lm4)
lm5 <- glm(dia_yes ~ BMI + male + Age + white + black + income_high + income_low + hs + own, family = binomial, data = df)
coef(lm5)
```

BMI의 coefficient는 0.09646225(lm2) -> 0.09640955(lm3) -> 0.09433545(lm4) -> 0.09425600(lm5)로 지속적으로 감소한다. 이는 추측컨대 `BMI`와 관계된 다른 변수인 hs, white, income_low, age 등이 지속적으로 추가되면서 BMI의 설명력이 감소하는 것에 따른 것일 것이다.



## (c)


```{r}
df2 <- df %>%
  cbind(1:nrow(df)) %>%
  rename(ids = '1:nrow(df)') 

df2_test <- df2 %>% filter(ids%%10 == 0)
df2_train <- df2 %>% filter(ids%%10 != 0)
y.dia <- df2_test$dia_yes
```

그런데... MSE는 여기서 적절한 지표가 아니므로 다른 지표를 알아봐야 한다. Cross-Entropy Loss가 해결책이 될 수 있다. (-0.5777604, -0.6239781, -0.6294386, -0.6321395, -0.6306247)의 값이 (lm1, lm2, lm3, lm4, lm5)에서 각각 산출되며, 아래의 코드에서 확인할 수 있다.

이 경우 test set에서 cross-entropy loss의 mean이 낮은 lm4을 고르는 것이 바람직하다. 다른 set lm5의 경우 과적합된 것으로 보인다.


### lm1

```{r}
lm1.pr <- glm(dia_yes ~ BMI, family = binomial, data = df2_train)

yhat.lm1 <- predict.glm(lm1.pr, df2_test, type = 'response')
-mean(y.dia*log(yhat.lm1) + (1 - y.dia) * (1-yhat.lm1))
```


### lm2

```{r}
lm2.pr <- glm(dia_yes ~ BMI + male + Age, family = binomial, data = df2_train)

yhat.lm2 <- predict.glm(lm2.pr, df2_test, type = 'response')
-mean(y.dia*log(yhat.lm2) + (1 - y.dia) * (1-yhat.lm2))
```


### lm3

```{r}
lm3.pr <- glm(dia_yes ~ BMI + male + Age + white + black, family = binomial, data = df2_train)

yhat.lm3 <- predict.glm(lm3.pr, df2_test, type = 'response')
-mean(y.dia*log(yhat.lm3) + (1 - y.dia) * (1-yhat.lm3))
```


### lm4

```{r}
lm4.pr <- glm(dia_yes ~ BMI + male + Age + white + black + income_high + income_low, family = binomial, data = df2_train)

yhat.lm4 <- predict.glm(lm4.pr, df2_test, type = 'response')
-mean(y.dia*log(yhat.lm4) + (1 - y.dia) * (1-yhat.lm4))
```


### lm5

```{r}
lm5.pr <- glm(dia_yes ~ BMI + male + Age + white + black + income_high + income_low + hs + own, family = binomial, data = df2_train)

yhat.lm5 <- predict.glm(lm5.pr, df2_test, type = 'response')
-mean(y.dia*log(yhat.lm5) + (1 - y.dia) * (1-yhat.lm5))
```

